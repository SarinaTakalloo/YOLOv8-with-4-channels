{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66999d-e644-4458-803d-4964ec771ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names:\n",
    "#     0: healthy\n",
    "#     1: stressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ab07ed-7ade-4ccb-8437-534254931c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import KFold\n",
    "import glob, os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c84bf32-4693-4b1c-a375-56976bed4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset path\n",
    "dataset_path = Path(r'C:\\Users\\amalti\\Desktop\\sarina\\test\\train')\n",
    "\n",
    "# Get all label files\n",
    "labels = sorted(dataset_path.rglob(\"labels/*.txt\"))\n",
    "\n",
    "# Define classes (assuming 2 classes for example)\n",
    "classes = ['stressed', 'healthy']\n",
    "cls_idx = list(range(len(classes)))\n",
    "\n",
    "# Create a DataFrame with indices from the filenames (using the full name)\n",
    "indx = sorted([l.name for l in labels], key=lambda x: int(''.join(filter(str.isdigit, x.split('.')[0]))))\n",
    "labels_df = pd.DataFrame(0.0, columns=cls_idx, index=indx)\n",
    "\n",
    "for label in labels:\n",
    "    lbl_counter = Counter()\n",
    "\n",
    "    with open(label, 'r') as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    for l in lines:\n",
    "        try:\n",
    "            class_index = int(l.split(' ')[0])\n",
    "            lbl_counter[class_index] += 1\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Invalid class index in line {line_num} of file {label}: {l.strip()}. Exception: {e}\")\n",
    "\n",
    "    labels_df.loc[label.stem] = lbl_counter\n",
    "\n",
    "# labels_df = labels_df.fillna(0.0)  # Replace `NaN` values with `0.0`\n",
    "# print(labels_df.head(10))  # Print only the head of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777829b3-e731-4ff7-bae7-a01fd6cb5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0    1\n",
      "image1   4.0  2.0\n",
      "image2   4.0  2.0\n",
      "image3   4.0  4.0\n",
      "image4   4.0  4.0\n",
      "image5   3.0  5.0\n",
      "image6   2.0  7.0\n",
      "image7   5.0  4.0\n",
      "image8   3.0  5.0\n",
      "image9   5.0  5.0\n",
      "image10  3.0  6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = r'C:\\Users\\amalti\\Desktop\\sarina\\test\\train'\n",
    "\n",
    "# Get all label files\n",
    "labels = sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(dataset_path) \n",
    "                 for f in filenames if os.path.splitext(f)[1] == '.txt' and 'labels' in dp])\n",
    "\n",
    "# Define classes (assuming 2 classes for example)\n",
    "classes = ['stressed', 'healthy']\n",
    "cls_idx = list(range(len(classes)))\n",
    "\n",
    "# Create a DataFrame with indices from the filenames (using the full name without extension)\n",
    "indx = sorted([os.path.splitext(os.path.basename(l))[0] for l in labels], \n",
    "              key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "labels_df = pd.DataFrame(0.0, columns=cls_idx, index=indx)\n",
    "\n",
    "# Populate the DataFrame with label counts\n",
    "for label in labels:\n",
    "    lbl_counter = Counter()\n",
    "\n",
    "    with open(label, 'r') as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    for line_num, l in enumerate(lines, start=1):\n",
    "        try:\n",
    "            # Classes for YOLO label use integer at the first position of each line\n",
    "            class_index = int(l.split()[0])\n",
    "            lbl_counter[class_index] += 1\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Invalid class index in line {line_num} of file {label}: {l.strip()}. Exception: {e}\")\n",
    "\n",
    "    labels_df.loc[os.path.splitext(os.path.basename(label))[0]] = lbl_counter\n",
    "\n",
    "# Replace `NaN` values with `0.0`\n",
    "# labels_df = labels_df.fillna(0.0)\n",
    "print(labels_df.head(10))  # Print only the head of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7c84a7-f3b3-4b6c-b72d-40375fafda63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image1496</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image1497</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image1498</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image1499</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image1500</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1\n",
       "image1     4.0   2.0\n",
       "image2     4.0   2.0\n",
       "image3     4.0   4.0\n",
       "image4     4.0   4.0\n",
       "image5     3.0   5.0\n",
       "...        ...   ...\n",
       "image1496  3.0   7.0\n",
       "image1497  2.0  10.0\n",
       "image1498  4.0  10.0\n",
       "image1499  3.0   8.0\n",
       "image1500  5.0  10.0\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98360401-fc46-44fe-b609-af92b85bee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksplit = 3\n",
    "kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)   # setting random_state for repeatable results\n",
    "\n",
    "kfolds = list(kf.split(labels_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9d13c5-d056-4853-b5b5-f73690cf290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [f'split_{n}' for n in range(1, ksplit + 1)]\n",
    "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n",
    "\n",
    "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
    "    train_totals = labels_df.iloc[train_indices].sum()\n",
    "    val_totals = labels_df.iloc[val_indices].sum()\n",
    "\n",
    "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
    "    ratio = val_totals / (train_totals + 1E-7)\n",
    "    fold_lbl_distrb.loc[f'split_{n}'] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c6a414-ca3a-44c8-952a-3fdce718d4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.492632</td>\n",
       "      <td>0.487887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.513558</td>\n",
       "      <td>0.4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.493991</td>\n",
       "      <td>0.514554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1\n",
       "split_1  0.492632  0.487887\n",
       "split_2  0.513558    0.4978\n",
       "split_3  0.493991  0.514554"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_lbl_distrb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2b2609e-c31d-47ba-acec-670966f16935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold Cross Validation Setup\n",
    "base_path = r'C:\\Users\\amalti\\Desktop\\sarina\\test'\n",
    "kfold_base_path = os.path.join(base_path, 'kfold')\n",
    "\n",
    "# Remove existing folder if it exists\n",
    "if os.path.isdir(kfold_base_path):\n",
    "    shutil.rmtree(kfold_base_path)\n",
    "\n",
    "# Create new folder\n",
    "os.makedirs(kfold_base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93f5ed97-f893-4384-bed5-eb4d481e18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store image and label paths for future use\n",
    "TARGET_IMAGES_PATH = r'C:\\Users\\amalti\\Desktop\\sarina\\test\\train\\images'\n",
    "TARGET_LABELS_PATH = r'C:\\Users\\amalti\\Desktop\\sarina\\test\\train\\labels'\n",
    "image_paths = glob.glob(os.path.join(TARGET_IMAGES_PATH, \"*.jpg\"))\n",
    "label_paths = glob.glob(os.path.join(TARGET_LABELS_PATH, \"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "913d8797-ae6d-487d-84b2-afb6c123dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dccd8817-adf5-48cd-9a20-8a98022b8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml Paths\n",
      "['C:\\\\Users\\\\amalti\\\\Desktop\\\\sarina\\\\test\\\\kfold\\\\data_0.yaml', 'C:\\\\Users\\\\amalti\\\\Desktop\\\\sarina\\\\test\\\\kfold\\\\data_1.yaml', 'C:\\\\Users\\\\amalti\\\\Desktop\\\\sarina\\\\test\\\\kfold\\\\data_2.yaml']\n"
     ]
    }
   ],
   "source": [
    "yaml_paths = list()\n",
    "train_txt_paths = list()\n",
    "val_txt_paths = list()\n",
    "\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kfolds):\n",
    "    # Get image paths for train-val split\n",
    "    train_paths = [image_paths[j] for j in train_idx]\n",
    "    val_paths = [image_paths[j] for j in val_idx]\n",
    "    \n",
    "    # Create text files to store image paths\n",
    "    # Create text files to store image paths\n",
    "    train_txt = os.path.join(kfold_base_path, f\"train_{i}.txt\")\n",
    "    val_txt = os.path.join(kfold_base_path, f\"val_{i}.txt\")\n",
    "\n",
    "    # Write images paths for training and validation in split i\n",
    "    with open(str(train_txt), 'w') as f:\n",
    "        f.writelines(s + '\\n' for s in train_paths)\n",
    "    with open(str(val_txt), 'w') as f:\n",
    "        f.writelines(s + '\\n' for s in val_paths)\n",
    "\n",
    "    train_txt_paths.append(str(train_txt))\n",
    "    val_txt_paths.append(str(val_txt))\n",
    "\n",
    "    # Create yaml file\n",
    "    yaml_path = os.path.join(kfold_base_path, f'data_{i}.yaml')\n",
    "    with open(yaml_path, 'w') as ds_y:\n",
    "        yaml.safe_dump({\n",
    "            'train': os.path.basename(train_txt),\n",
    "            'val': os.path.basename(val_txt),\n",
    "            'names': classes\n",
    "        }, ds_y)\n",
    "    yaml_paths.append(yaml_path)\n",
    "print(\"Yaml Paths\")\n",
    "print(yaml_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5008c4-cb14-40be-8816-65035737f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ksplit):\n",
    "    model = YOLO('yolov8s.pt')\n",
    "    dataset_yaml = yaml_paths[i]\n",
    "    print(f\"Training for fold={i} using {dataset_yaml}\")\n",
    "    model.train(data=dataset_yaml, batch=batch, project=project, epochs=100, verbose=False, workers=28)\n",
    "    result = model.metrics # Metrics on validation set\n",
    "    results.append(result) # save output metrics for further analysis\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e99b1fd-68d0-4adc-b445-da442eca5ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.615071</td>\n",
       "      <td>0.623538</td>\n",
       "      <td>0.591094</td>\n",
       "      <td>0.449511</td>\n",
       "      <td>0.463669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.355710</td>\n",
       "      <td>0.350580</td>\n",
       "      <td>0.420025</td>\n",
       "      <td>0.411607</td>\n",
       "      <td>0.412448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.270952</td>\n",
       "      <td>0.273026</td>\n",
       "      <td>0.199180</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0.081112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.948898</td>\n",
       "      <td>0.953456</td>\n",
       "      <td>0.979138</td>\n",
       "      <td>0.831956</td>\n",
       "      <td>0.846603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
       "mean              0.615071           0.623538          0.591094   \n",
       "std               0.355710           0.350580          0.420025   \n",
       "min               0.270952           0.273026          0.199180   \n",
       "max               0.948898           0.953456          0.979138   \n",
       "\n",
       "      metrics/mAP50-95(B)   fitness  \n",
       "mean             0.449511  0.463669  \n",
       "std              0.411607  0.412448  \n",
       "min              0.067993  0.081112  \n",
       "max              0.831956  0.846603  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_values = dict()\n",
    "\n",
    "for result in results:\n",
    "    for metric, metric_val in result.results_dict.items():\n",
    "        if metric not in metric_values:\n",
    "            metric_values[metric] = []\n",
    "        metric_values[metric].append(metric_val)\n",
    "\n",
    "metric_df = pd.DataFrame.from_dict(metric_values)\n",
    "visualize_metric = ['mean', 'std', 'min', 'max']\n",
    "metric_df.describe().loc[visualize_metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe782da-81c2-4d24-8b92-740d08be95cd",
   "metadata": {},
   "source": [
    "# Kfold RGB\n",
    "## I tried to add patience and reduce number of epochs to resolve overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954412fc-c5e4-4f1d-b0fe-feb81b3dc0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold=0 using C:\\Users\\amalti\\Desktop\\sarina\\test\\kfold\\data_0.yaml\n",
      "New https://pypi.org/project/ultralytics/8.2.27 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.22  Python-3.12.3 torch-2.3.0 CUDA:0 (NVIDIA A40-12Q, 12288MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=C:\\Users\\amalti\\Desktop\\sarina\\test\\kfold\\data_0.yaml, epochs=75, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=28, project=kfold_demo, name=split0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=kfold_demo\\split0\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir kfold_demo\\split0', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\amalti\\Desktop\\sarina\\test\\train\\lab\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\amalti\\Desktop\\sarina\\test\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\amalti\\Desktop\\sarina\\test\\train\\label\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\amalti\\Desktop\\sarina\\test\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "project = 'kfold_demo'\n",
    "\n",
    "# Specify the save directory for training runs\n",
    "save_dir = r'C:\\Users\\amalti\\Desktop\\sarina\\kfold_demo'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# yaml paths\n",
    "yaml_paths = ['C:\\\\Users\\\\amalti\\\\Desktop\\\\sarina\\\\test\\\\kfold\\\\data_0.yaml', 'C:\\\\Users\\\\amalti\\\\Desktop\\\\sarina\\\\test\\\\kfold\\\\data_1.yaml', 'C:\\\\Users\\\\amalti\\\\Desktop\\\\sarina\\\\test\\\\kfold\\\\data_2.yaml']\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "ksplit = 3\n",
    "\n",
    "# hyperparameters: \n",
    "batch = 16\n",
    "epochs = 75\n",
    "patience = 5\n",
    "# freeze= \n",
    "weight_decay = 0.0005\n",
    "# lr0=\n",
    "\n",
    "results = list()\n",
    "for i in range(ksplit):\n",
    "    model = YOLO('yolov8s.pt')\n",
    "    name = f'split{i}'\n",
    "    dataset_yaml = yaml_paths[i]\n",
    "    print(f\"Training for fold={i} using {dataset_yaml}\")\n",
    "    model.train(data=dataset_yaml, batch=batch, project=project, epochs=epochs, verbose=True, workers=28, save_dir=save_dir, name=name)\n",
    "    result = model.metrics # Metrics on validation set\n",
    "    results.append(result) # save output metrics for further analysis\n",
    "    # clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dca637-bb36-4067-875d-3ac30feab6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values = dict()\n",
    "\n",
    "for result in results:\n",
    "    for metric, metric_val in result.results_dict.items():\n",
    "        if metric not in metric_values:\n",
    "            metric_values[metric] = []\n",
    "        metric_values[metric].append(metric_val)\n",
    "\n",
    "metric_df = pd.DataFrame.from_dict(metric_values)\n",
    "visualize_metric = ['mean', 'std', 'min', 'max']\n",
    "metric_df.describe().loc[visualize_metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb27cb-2de0-4f9d-ab56-3e5b34969f37",
   "metadata": {},
   "source": [
    "## validation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4d803-8738-4ac3-afdc-f945656f8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r'C:\\Users\\amalti\\Desktop\\sarina\\kfold_demo\\split0\\weights\\best.pt')  # load a custom model\n",
    "model.overrides['conf'] = 0.7  # NMS confidence threshold\n",
    "# model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ee97e-ba7e-4708-9f15-a562f91772b7",
   "metadata": {},
   "source": [
    "# Kfold RGB\n",
    "## I tried to add patience and reduce number of epochs to resolve overfitting and freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b142b-3486-4286-980e-a68da4ad2ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
